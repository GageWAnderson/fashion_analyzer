{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from typing import Annotated, Union\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from functools import partial\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "import operator\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from langchain.tools import StructuredTool\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain.schema import BaseMessage\n",
    "from langgraph.prebuilt import ToolExecutor, ToolInvocation\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts.base import format_document\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    BaseMessage,\n",
    "    get_buffer_string,\n",
    ")\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "fast_llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "local_llm = ChatOllama(model=\"llama3.1\", temperature=0)\n",
    "local_embedding_model = OllamaEmbeddings(model=\"nomic-embed-text:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "async def qa_tool(input: Annotated[str, \"A basic question from the user that you can answer quickly from memory.\"]):\n",
    "    \"\"\"This tool answers user questions from your long term memory.\n",
    "    Use this tool when the question doesn't require data from the past year\"\"\"\n",
    "    return await local_llm.ainvoke(input)\n",
    "\n",
    "@tool\n",
    "async def search_tool(input: Annotated[str, \"A search query to search Tavily for.\"]):\n",
    "    \"\"\"This tool searches Tavily for information relevant to the user's query.\"\"\"\n",
    "    return TavilySearchResults(query=input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Protocol\n",
    "\n",
    "\n",
    "class ToolCallingLanguageModel(Protocol):\n",
    "    def bind_tools(self, tools: list[StructuredTool]) -> None: ...\n",
    "\n",
    "    async def ainvoke(self, messages: list[BaseMessage]) -> BaseMessage: ...\n",
    "\n",
    "\n",
    "ToolCallingLanguageModel = Union[ChatOpenAI, ChatOllama]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "\n",
    "async def should_continue(state: AgentState) -> str:\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if not messages:\n",
    "        return \"continue\"\n",
    "    \n",
    "    original_question = messages[0].content # TODO: Come up with a better way to track the original question in state\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    prompt = f\"\"\"Given the user's original question: \"{original_question}\"\n",
    "and the last message in the conversation:\n",
    "{last_message.content}\n",
    "\n",
    "Is the agent's task complete? Answer with 'Yes' if the task is done, or 'No' if more actions or information are needed.\"\"\"\n",
    "\n",
    "    response = await local_llm.ainvoke([HumanMessage(content=prompt)])\n",
    "    print(response.content.strip().lower())\n",
    "    return \"end\" if \"yes\" in response.content.strip().lower() else \"continue\"\n",
    "\n",
    "\n",
    "async def agent(model: BaseLanguageModel, state: AgentState) -> AgentState:\n",
    "    return {\"messages\": [await model.ainvoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "async def action(executor: ToolExecutor, state: AgentState) -> AgentState:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if not hasattr(last_message, \"tool_calls\") or not last_message.tool_calls:\n",
    "        raise ValueError(\"Last message does not contain tool calls\")\n",
    "    \n",
    "    tool_call = last_message.tool_calls[0]\n",
    "    print(tool_call)\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "                name=tool_call[\"name\"],\n",
    "                content=str(await executor.ainvoke(ToolInvocation(\n",
    "                    tool=tool_call[\"name\"],\n",
    "                    tool_input=tool_call[\"args\"]\n",
    "                ))),\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "class ChatGraph:\n",
    "    graph: CompiledStateGraph\n",
    "\n",
    "    @classmethod\n",
    "    def from_dependencies(\n",
    "        cls,\n",
    "        llm: BaseLanguageModel,\n",
    "        tools: list[StructuredTool],\n",
    "    ) -> \"ChatGraph\":\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"agent\", partial(agent, llm.bind_tools(tools)))\n",
    "        graph.add_node(\"action\", partial(action, ToolExecutor(tools)))\n",
    "        graph.add_edge(START, \"agent\")\n",
    "        graph.add_conditional_edges(\n",
    "            \"action\", should_continue, path_map={\"continue\": \"agent\", \"end\": END}\n",
    "        )\n",
    "        graph.add_edge(\"agent\", \"action\")\n",
    "        return graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k9/fclgtm1j483d4r4tbjfzpz1w0000gn/T/ipykernel_5603/1967508518.py:60: LangGraphDeprecationWarning: ToolExecutor is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  graph.add_node(\"action\", partial(action, ToolExecutor(tools)))\n"
     ]
    }
   ],
   "source": [
    "chat_graph = ChatGraph.from_dependencies(llm=local_llm, tools=[qa_tool, search_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAF9AH0DASIAAhEBAxEB/8QAHQABAAIDAQEBAQAAAAAAAAAAAAUGAwQHCAECCf/EAFMQAAEDAwICBQQJEAcHBQAAAAECAwQABREGEgchExUiMUEUFpTRCBcyUVRWYXHTIzU2QlJTVXJ0dZGSk5WxszM3gbK0xNIJJENXYsHUJUVkg6H/xAAbAQEBAAMBAQEAAAAAAAAAAAAAAQIEBQMGB//EADQRAAIAAwQGBwkBAQAAAAAAAAABAgMREiExUQQTYXGR0RQjM0GhscEFFTJSU2KS4fCB8f/aAAwDAQACEQMRAD8A/qnSlQV2u0uTcBabSEiUEhcmY4NzcRB7uX2zivtU9wGVK5bUrzhhcboipVJl+Q1GbLjziGmx3qWoJA/tNR51VZR/7xA9JR660GOH9lKw9Pii9zMYVLuoD6zzzyBG1HzISkfJW/5rWUD60QPRkeqvWkld7YuPnnVZPwxA9KR66edVk/DED0pHrr75rWX8EQPRkeqnmtZfwRA9GR6qdTt8C3Hzzqsn4YgelI9dPOqyfhiB6Uj11981rL+CIHoyPVTzWsv4IgejI9VOp2+AuPnnVZPwxA9KR66edVk/DED0pHrr75rWX8EQPRkeqnmtZfwRA9GR6qdTt8BcbMO7QbiSIsyPJI7wy6lf8DW3UFM0JpyePq9jt6lDucTGQlaflSoAEH5Qa03UTNFgvpfk3Sxg/VWn1dK/DT92hXunEDvKVFSgMkE4CaWII7oHfk+f/CUTwLTSvy24h5tLjakrbWApKknIIPcQa/Va5BSlKAxyH0RmHHnDhttJWo+8AMmoDh+yo6Yi3B4Dyy6DrCQoZ5rcAIHP7lOxA+RAqauUTy+3SoucdM0tvPvZBH/eorQUryvRdlUQUuIiNtOJUMFLiBsWkj5FJI/srYXYuma9S9xPUqvar4iaU0GYo1Nqaz6dMrd5OLtPai9Ntxu2dIobsbk5x3ZHv1Aj2QfC0pKvbK0htBAJ6+i4B/afIa1yG/xO4nWzhXZIVwuMSfcXbhPZtkG32xkOyJUl3OxtAUpKckJUcqUBgHnXOdfeyFvunr3wxbtmhNQPsalmTGplufjMNz0Blh5QaQlchKEr3NheSSktpJCskAyHEjWOj+L2kX7LpyHYuMC0vNuybLaNQRUSY7YJxJbX0g2LQrbg7kHtclDxo8Th7xStOkOF18nW57VOotKX2bLXZpF0aVM6vfakMNNqlLIbdeaQ63lRICsHmT3gdO4g8fIXDR9a7vpHVi7RHjtyp16iW5DsOChXeXFBzcdnero0r2iv3qTjzbLHxBGi4On7/qS+qtjN4SizsMraMZx1be/pHHUJG0t88kZCk7dxyBxLjJwb1rxNumu13DQCNRv6gtDDOnpVxvDAj6bWYoS80WyonpQ9vUHGkqC8pBUkDl1PhxojUUDi+NS3O0Kt0B7Q9qtai4+04puY08+t1khCzkpDiO0MpOeRNAfvg7xpvvELXevLHctJ3KBDst6egRrjsYTHbbQwwoNukPqWXVFxSwUo27VJyQcgdkrhulOueDnEXiHIv9sjRdC328deDV0i6RmI0IKisslp5txYWD0jKUggEHpBzHdVzR7ILhc4cI4k6QUQCcJvsU8gMk/0nvCgL/SqTa+OPDi+XGNb7dxA0tcJ8lwNMRYt6jOOurJwEpSlZKiT3ACrtQFY0NiC1dbInaGrRMMZhKc4SwptDrSRnwSlwIHyIqz1WdJJ8ovOqZ6c9E/cAy2SMZDTLbavn7aXB/ZVmrYn9o3urvpf4mTxFKUrXMRVYeCtG3KVLDal2Oa4XpHRpKlQ3jjc4QP+ErGVEe4VlRylSlIs9K9II7NU708SpmsjyO6x2n0dBMYWnc26nC0qB8Qe7HzU6tifBWf2Y9VQsnQdrcfcfiKl2h5wkrVbJS2EqJOSS2k7CSeeSnPfz5msR0Q/8ab8P/va+jr0sSnhFTeuVRRFjZiMRyS0y22TyJQkCstVbzIf+NN+/btfRU8yH/jTfv27X0VNXL+fwZaLMtNK5XrG23Wx6m0LAi6pvHk95u7sKX0rzO7o0wJb42fUx2t7Dfv8t3LxFr8yH/jTfv27X0VNXL+fwYosyzuNodQULSFpPelQyDWDq2J8FZ/Zj1VX/Mh/40379u19FTzIf+NN+/btfRU1cv5/BiizLCiBFbUFJjMpUDkEIAIqIu1/ckyXLTZVtv3X3Lr3u2oKfFbv/Vg9lvvUcdydyk63mEw/ym3m9T2yMFpyeptKvnDWzPzHkfGp63WyJaIiIsKM1EjpyQ2ygJGT3nl4nxPjTq4L07T3Xf2wXI/FmtMexWuLb4oUGI6AhJWdyle+pR8VE5JPiSTW7SleDbidXiYilKVAKUpQClKUApSlAc/4klI1zwpySCdRSNuPE9UXD5R4Z9/5vEdArn/EjPnxwpwU484ZGdwGfrRcO7PPPzc8Z8M10CgFKUoBSlKAUpSgFKUoBSlKAUpSgFKUoDnvEoA664TdpKcajkYBHNX/AKRceQ5d/j4dxroVc94l48+uE2SQfOORjlnJ6nuP6K6FQClKUApSlAKUpQClKUApSlAKVWrzqiW3cXbdZ4bMyUwEmQ7KeU0yyVAEJyEqKllJ3bRgAYyRkZjevNYfAbH6U99HW1Do0cSrct7RaF3pVI681h8BsfpT30dOvNYfAbH6U99HWXRY81xQoeUfZNezcmcJuNVo09dOHbrzmmrkq4xpDd1G24Muw5DCFJBYOw4kZOCcFCk5PM17O0hepOpNJ2W7TLeu0y58FiU9AcXvVGWttKlNFWBkpJKc4GcdwrgHGL2P7vGrXei9U3uBZkzNNv8ASFpDzikzWgd6WXMt+5Cxu5fdKHjkdf681h8BsfpT30dOix5rihQu9KpHXmsPgNj9Ke+jp15rD4DY/Snvo6dFjzXFChd6VSxqrUNtQqRcrXBehtjc6bfIcU8hPLKkoU2N+BkkAg8uWTgVb40hqZHafYcS6y6gLQ4k5CkkZBHyEV4zJUUu+IUMtKUrxIKUpQClKUBQbCc37VxPf1t3+/8A7rHqbqDsH191d+dv8tHqcrrzMVuXkjKLEUpSvMxFKUoBStG43y32d6CzOmsRHp74jRW3nAlT7u1StiAfdK2pUcDwST4VvUAIyMHurFwuUVcNNKE95tUX+UmstYeFn9Wek/zVF/lJrGb2L3ryZe4tNKUrnEFKUoBSlKAoFg+vurvzt/lo9TlQdg+vurvzt/lo9TldeZity8kZRYnlH2Rmo79JuuvrloybqWPN0TbkSJstGoPIrdFeDPlCUIiBtYlKKCkrDmE4UAFA1r8X9aXS5amvjF11HqfTr69KRp2kIWmVvoTPnLS4XtwaB6VYc6BAbWdoSrOOe4d41VwH0Jra+y7ve9PtzpsxpLMsKkPIZlJSMI6VpKw24UjklS0kpwMEYFc44p+x5u97vkJ3StvszcONaWLW1JmX+7wpjKWt4bKjHcKXwkK5dJhWd2VHPLWaZiU4r4ja11v5loVLYVpjTdpW7Ej6tftDrkl5lRefU6hh5cgJUjZ2lbQU5IUV5E9aLJra9cSNEaO1vqu5sShpKdLuQ07dHI6Jbrc1ltlZcQltW7o3ElSkBBKsj3JIPSF+x+07qTT+mWtaId1NqK0W5uA5f0yX4kqSAkb962nEqUlSgVbVKUMkk5JJNttnDvTtmvFqukK2ojTbXbDZoa23FhLMMqQotBG7bjLTfMjPZ7+ZqqFg8sPxJXETTPBROoL5eZEuJra5WNVwj3J6M+8215c224pbSk/VdrCB0nuua+fbVn2JCipgw2IyFuuIZbS2FvOFxagBjKlKJKjy5knJqmT+CWirnpLzZk2ULs4nuXRDQkvJcalLdU6p5DoWHEK3uLOUqGAogYHKrdaLXGsdqh26GhTcSIyhhlC3FOKCEpCUgqUSpRwBzJJPiasKoDbrDws/qz0n+aov8pNZqw8LP6s9J/mqL/KTVm9i968mXuLTSlK5xBSlKAUpSgKBYPr7q787f5aPU5WjdbPcrPeJs+2Q+s4s9aXX4qXUtutOhCUbkbiElJShORkEFJPa3Hbpda3/AOJtz9Kh/TV2LpiUULWC70u7azJ3k3SoTrW//E25+lQ/pqjrDra4anhuy7bpS5yYzch6KXenipSXGnFNuBOXhkBaFJyORxyJqav7l+UPMlC2UqE61v8A8Tbn6VD+mp1rf/ibc/Sof01NX9y/KHmKE3SuYcL+PVs4zWuXP0dapl5YhvdBJSiRGbdZXzwFtrdCgDg4JGDg4JwaunWt/wDibc/Sof01NX9y/KHmKE3WHhZ/VnpP81Rf5SajN2pLq2Y7Nids63OyZc6QytLQ8VBLS1FRxnA5ZIGSBzq42i2M2W1Q7fG3eTxGUMN7zlW1KQkZPicCvCe1DLsVTbawdcK5by4I26UpXPMRSlKAUpSgFKUoCocUdRy9P6XLNqUBfrs+3arWOXKQ6SOkwe9LSA48ofcsqqb0vpyFpDTlssdtQpuBb46IzIWrcopSkAFR8VHGSe8kk+NVGFt1lxfmStxXb9IseRNJKRtVcJCEuOqznvbYLSQf/kuDwroVAK/DwWplYbIDhSdpPdnwr90oD+e/sTvYWa74X8WrPqvVV/k6TeeU8+m0WcCQZTaFHdHlvpJabCstrCR0m9IXgtrTkf0IqI1TBem2dxUVUwS4y0S2W4UgMLfW2oLDJUezsXt2KChjCj3ciN+3y/L4EaV0D0bp2kudDITtcbyAdqh4KGcEe/QGxSlKAUpSgFKUoBSlKAVHajv0TS2nrpergstQLdFdmSFgZ2ttoK1H9ANSNc941p6z07Z9PbFOJv8AeodvdSk+6YDnTvpPLuLLDqT8hoCQ4RWGbYdA23rZBRfJ++6XNJ5lMuQsvOoz7yFLKE+8lCRyxirc8+3HRvcUEJ981kqN1B9bVfjD+NAZutofwhFOtofwhFck1zxU0vw4XDbv908lkzd3k0ViO7JkOhPulJaaSpZSMjKsYGeZrQvnHLROnLbaJ029ENXdkyYTceI++880ACXOibQpYSMjKikAeNAdq62h/CEVA6dfYstzu1vajCNai4JseWZhdDrry3FPoCFdpvarCse5w6NuMEDmdz456HtMeyvO31D6L1FXNtohR3pSpjSCgKLSWkKKiN6cpA3Y3HGEqIrmuPZHab0zZtE3u39LfLZqS5iA3KhxZDnRNgK6VWxDSlFaVICeiICyd2AdisAejetofwhFOtofwhFcKb4uQZXEVuysz2GoDen3L3JjyrdMZmBG5rY4hSmw3sCXMKRnpAogYGFAbWk+OeiNb3aDbbLexLlT2FSIe6K+03KQkBS+icWgIcKQe0lJJTg5AwcAdr62h/CEU62h/CEVyOPxX0rK0vZ9RNXTdZ7vNat8KT5O6Olfce6FCNu3cnLg25UAB3k451H3fjtoSxajdsc7UDTE9l5Md5XQOqjsOqxtbcfCC02o5HZUoHmOVAdwYnx5K9jTqVqxnArYqsac+uB/EP8A2qz0ApSlAK57xH2+f3CnpNuzr6Ts3Z/pOqp2MY8dvSd/LGfHFdCrn/GvdbdLQdSJUpI01c413eIJ5RkKLcpRx9zHdfVjx2ju7wB0Co3UH1tV+MP41IggjI5itK8x3JMFTbSd6yQcUB5m1e5cOH3H06zk6du+obFctPt2lEiyQ1TH4LzchbhSppGVhtwLSdwBGUYOORrRn32fpri8zxDk6Q1LNs170yzb22YltVIm299uQ44WnWUEqQFhxJzzAUjBIr0P1LN+8H9YeunUs37wf1h66A8r8GeH+o9Na24dSbrZZMBvq7UMp5kNlbVu8qmsvMx1rT2Ur2E9nPeFAd1abumb/ZtGw7h5u3WSiy8Upt6dgxoi1SVwTIkpDrLWNzicPJUNoORkjNetOpZv3g/rD11rs256TKfQ2ltxyOQ24lDiSptRAVtUM8jtKTz8CDQHBtRxrjqjisxfollurdvk8P7lHSqTBcaUh9ciOpDKwR2XCEqIQe1gHlyqLsOlrxH017GhCrRObftCGU3BJjLCoQ6pdbUHhj6n2yEndjmQO+vSvUs37wf1h66dSzfvB/WHroDx1b4l/gcM+H2gV6Q1Eq8WPWMF2fJTbXDEbjouRc6dL2Nq0FBByknaMlW0DNNP8NYsB6/6L1vpriFdnbje5S/KLPPndUTosmQXEvOdG8llvCV9tKgD2ScKJr2L1LN+8H9YeunUs37wf1h66Ay6YbDUxKE52pbIGTk45VaagbJbpMWYVutFCdhGcj5KnqAUpSgFYZkNi4w34sppD8Z9tTTrTgylaFDBSR4ggkVmpQFC4QTHYVmm6SmureuOlnxbS46crfjbQqK8SSSrcypAUrxcQ4O8Gr7XPdbrVo7XentWJUU2+aUWC7jOEhDi8w3j+I+otj5Jaye4VZNI6707r6NOk6bvMO+xIUkw3pMB0PMh4IQ4UBacpVhLiM7SQCSDzBAAnqUpQGvcLhFtMCTOmyWocKM2p5+RIWENtNpBKlqUeSUgAkk8gBUVo+2vwbUuRNi26NdJ7ypc02sKLTjhwlKtyu0shtLadxxnaMADAGvql1u6z7fp1Ei3qclkyZkKax05ehIIDgCPc81raRlXLClEZIqy0ApSlAKUpQClKUApSte4STDgSZAAUWmlOAHxwCaqVXQEdeNZ2DT0gMXO9QIEgp3BmRJQhePf2k5x8tR/tp6O+M9q9LR66itGMJTpq3yT25MxhuTJfV7t51aAVLUff/gMAcgKm66LkSoHZdW1tS9GZXHnv2ZOkbf7ILhum26b4mxbNPh73Da+sgiFdQShQafAVglJbCkKVkA5yBncmA/2ek2Dwu4H3Oy6onw7JdOv5Tpjyn0JUpHRspCxzwpJKDhQ5HFeo6U1UnJ8VyJcYfbT0d8Z7V6Wj109tPR3xntXpaPXWalNVJyfFchcVzTPFPS01643V7V0RTMx7EWLL6OOqM0gbNuM7juUFuZVzw4BgYqd9tPR3xntXpaPXWalNVJyfFchcY2+J+kHVhKdTWkkkDnMbHjgePv8qsyVBaQpJCkkZBHcarhAUCCMg8iDWpw/c8nev9rb7MSBNSiM34NIWw2soT/0hSlEDkACAAABXnMkwWXFBW7O/Zkhc8C30pStEgpSlAK0b59ZLh+Tuf3TW9WjfPrJcPydz+6azg+JFWJU9HfYjZPyFj+WmpeojR32I2T8hY/lpqXrqTfji3sPEUrilv8AZGvM8Wbfom/WG32p25SnYcVyJqCPNlIcQhS0eURkAKZStKDg5VgkA4zUpofjHqDiPPYn2DRBf0M/LcjNagkXVtp51CFqQp9EbYSWtyVYJWFEc9vOvG0mQ6vSvOvDnifxHvmkOJ828WKDKTabndY8ZbF86JxBZcCfJkkRcJShG4peOVKKRlAzkSel+NNy81uHdi0vp2XqzUl10vGvzzV3vAbMaKpCAFvyi0S44paikYbG4pUTtFS0gd3pXD43skpd9c0hBsGj3Z17v5ukd6BNuCIwt0qCttD7TywheU5WrtIBPZThJ3HbfuFfET2ydOy5r1tXZrlb7hJtVwt6ng8GJLCyhYS4AAtJ5EKwMgjkKqaYLlWhoX7INYflzP8AhWa360NC/ZBrD8uZ/wAKzWb7KPd6oyWDLlSlK5ZiKUpQCtG+fWS4fk7n901vVo3z6yXD8nc/ums4PiRViVPR32I2T8hY/lpqWUMgjJGfEVE6O+xGyfkLH8tNS9dSb8cW9h4nmXSXsddb6cRoKApzSnkGkr51kqcz04m3ZKulQ468oowh3Y8pW3KwtQHaQBVy4W8PeInChi36SgSdNT9CwJSzGmSTITckRFOKX0JbSno1LTu2hzeBgAlOa7RSvBQpEON6Z4Y6w0zK4gWdt6yStLail3G5xZKnXkTWX5ScltaNhQUJWVdoKzjHZqIs3BjWugWtCXjTEmwy9RWjSUbSt1h3V15ESQhoIUl1p1DZWClwOclI7SV/akV3ulWygcK0HwAvGkdVaGvUq6QrhKgO3yffHkhbZfl3BbS8sIwRsSUEdpQOADzJIF64TaDuGhG9XpnvRnjeNSTrwx5MpStrLyklCV5SMLGDkDI+U1e6UUKQFaGhfsg1h+XM/wCFZrfrQ0L9kGsPy5n/AArNZvso93qjJYMuVKUrlmIpSlAK17hGMyBJjhW0utqbBPhkEVsUqp0dQUDRslB09AhqIbmQmG40mMo9tlxKAFJUOR+UHGCCCORBqcrcvGj7DqJ1Lt1sluubqRtC5kVt1QHvZUDyqN9qvRfxRsX7tZ/010XPlRu06pvYn6oyuM1Kw+1Xov4o2L92s/6ae1Xov4o2L92s/wCmprZOb4LmS4zUquai4V6Q660v0eiYTyOsHOkchxGW2mk+SSO1ITt+qN52pCfBxTavtanfar0X8UbF+7Wf9NNbJzfBcxcZqVh9qvRfxRsX7tZ/009qvRfxRsX7tZ/001snN8FzFxkccS0grWoISOZUo4ArV4ft+UuX66t9qHcJiXIzng62hhtvpE/9JUlWDzBACgSFCtpjhnpCM4HGdK2RpY7lItzII8fuasgGBgchXnMnQWXDBW/PjtFywPtKUrSIKUpQClKUApSlAKUpQFd1NCTKvuknVW6VNMe5OOJfYd2IiEw5KOkdGe2khRbA59pxB+1zViquanipkX/SDhgzZZYuTjgeiubW4pMKSnpHh9sg7igD7txB8KsdAKUpQClKUApSlAKUpQClKUApSlAQt+nPxHWg04UApJOKiuuJn39X6BW9qf8Ap2PxT/GvIEvirxV1pcdU3TR0C9Lj2q6yrbbrdGgW1y3yTHcKD5S69IRIBWpJyUBOwEYC8ZIHqabIdmSre8646pyI8XmShZSEqLa0EqA5KG1ahg5GSD3gEbfXEz7+r9ArzHqbWPEK5XTi1KganVYGdHx482HbE2+O+C4baiQ4y84pJKm94UOzhQKyd2AkCZtut9YcYtYqtWntQI0XAtdjt10mvNQWpb0mRMQtxDYDoIS0hLZyRhRJxkYoDvlh1c3qKNEnW26MXK3yCC1JiOodacTnBKVJyCMgjkau1ebfYggj2P8AoIKOVeTHJAxn6suvSVAKUpQClKUApSlAKUpQClKUBXtT/wBOx+Kf41xl7gNa29U3C82rUOo9PN3KWJ8+12meGYcqRy3OKSUFSVL2jdsUndjnmvQL8RmSQXW0rI7twrH1XE+Dt/ooDi8vhPaJMnXLqn527WTaWbhtcRhlKYnkwLXZ5dgZ7W7tc+7lUPN9j/Z3LhaLhbb7qDT1wt9sZtDkq0TENLmxmhhtD4LZSojnhSQlQ3HBHLHY9QW1kXnTIbhTnEGesOKhKCWUJ8lf5yAe9vOAAOfSFo9wNTvVcT4O3+igOYcMNCQOGelLJpi1vSZEC2pDTLsxaVuqBWVdopSkE5J8BXWa1k22KlQUGEAg5BxWzQClKUApSlAKUpQClKUApSlAKUpQFd1NF6e/aRc8nuL3Q3JxfSQnAllnMOSndIH2zfa2gD/iKaPhVirwd7Lz2UXFzgzxxsdgttjsFwtpeTcLC4qNKLksuNOR1NOhEgBwpU6vs4HMNqx3V7e0wu7OaatK78iM3fVRGjPRCBDCZGwdKG8knZv3YyScY5mgJOlKUApSlAKUpQClKUApSuacbNTOwLbCscVZbeum8vrScFMdG3eAfAqK0J+Yq96tnR5EWkzYZUOLKjU1bxpW1Jdh6bjsSi2ooXcZWSwFDvCEJILnPPPckcuRNUl7iBrF9RUdTPMZOdseHGCR829tR/SahEpCEhKQEpAwAO4V9r76T7P0aTDZUCe1qvn6GNrIlvPnWPxuneiQ/oKefOsfjdO9Eh/QVE0rZ6No/wBKH8VyFpkfqq2y9bXzTt4vl3k3C5aekmZa5DkaKDGdIAKgAyAe4HCgRlIPeAas3nzrH43TvRIf0FRNKdG0f6UP4rkLTJbz51j8bp3okP6Cvo11rEHPnbNPyGJDx/IqnaL1bD11pe336A2+zDmoLjaJKQlwAKI5gEjw8Camqxh0fRokmpcNH9q5C0y5WTjDqO1OoTckR75FyAoobDEgDxIIOxXzbU/jV2LT2oYOqbU1cLe70sdzIIUNqkKHelQPMKB7xXmup7QGpHNK6vhL3EQLi6iHKb8Nyjtac+cLITn7lZz3CuRp/suVMluZJhpEr7sH/nkVOp6IpSlfEAUpSgFcN41BY17BKs9Gq2AI97IdVu/iiu5Vz7jDpB/UFpi3KAyp+4WxS1BlAyp1leOlQkeKuyhQHiUY8a6vsudDJ0qFx4Oq4lRxqlYwtMqPuZdwlxPZcRg4z3EZ5VUPMjUP/MO+eh2//wAav0CKJw4KvD1ZgXOvLQ049r28axlXXUtgsl+jXl+I1IuLL3l9vQFgRiwsSUJSkp2FOEYUSc7smu5eZGoP+Yd99Dt//jVNzNHWK5XNi5TrLbptzYADc6REbW8nHdhZTkf2VqTpT0iiaoln+n3A4bf9HW+93HjTKuzQnXG2RI7sWUVKSWH021CulbAOEL3JScjnyAzis9r6n19rdtnX8lp1iPpu3TLXFmyC004p1CzJkAZGVhQSnd3pHdXdlWO2rVcCq3xVG4gJmEsp/wB5ATsAc5dsbez2s8uXdWrcNHWC7NQm51jts1uEAIqJERtwRwAAA2COzgAd2O6vN6I61VMW2s72791fAFO9jjj2ktJ7TlPkysHOeXSLrpFVSZoiUgss2PUUzS9tZbCG7da4cMMI5kkgLYURnPcDj5K1/MjUP/MO++h2/wD8atmXalQQwWW6JLu5guda84LU00lrPTKfZS3jv3lxIT/+4rT09aZtniuNTr3Mvril7kvzGmG1IGANoDTaBjx5gnn31e+GmlnNUapjS1tk2u1Oh91wjkt9OC22D4lJws+9tSPtqs6dDJlObHdRfyLDid/pSlfl5RSlKAUpSgOeaw4PQ75MeuFqldTz3VFbqOiDkd5R71KRkEKJ71JIySSQo1R3eEOsWVEJatEgeC0TXE5+cFrl+k13uldeT7V0mTDYTqln/VLXM4B7U+s/gVr/AHgr6KntT6z+BWv94K+irv8AStj31pOS4fsXZHAPan1n8Ctf7wV9FT2p9Z/ArX+8FfRV3+lPfWk5Lh+xdkcA9qfWfwK1/vBX0VfRwm1mTjyO1D5TcF4/k136lPfWk5Lh+xdkccsnA64yXUrvt0ZjsAgmNa8qUr5C6sDA+ZAPvEV1i1WqHY7exBgR0RYjKdrbTYwB4n5ySSSTzJJJrbpXN0nTJ2lPrYrsu4VFKUrSIKUpQH//2Q==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_graph(graph: CompiledStateGraph):\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "draw_graph(chat_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-09-29T20:43:30.377572Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'search_tool', 'arguments': {'input': '2024 US presidential election favorite'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 1790306416, 'load_duration': 27429750, 'prompt_eval_count': 267, 'prompt_eval_duration': 1114032000, 'eval_count': 22, 'eval_duration': 647743000}, id='run-242aee72-4cb5-4ffc-8c84-870a71e09d15-0', tool_calls=[{'name': 'search_tool', 'args': {'input': '2024 US presidential election favorite'}, 'id': '641dfdbd-50a1-414c-aa23-6ceb327921e6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 267, 'output_tokens': 22, 'total_tokens': 289})]}\n",
      "{'name': 'search_tool', 'args': {'input': '2024 US presidential election favorite'}, 'id': '641dfdbd-50a1-414c-aa23-6ceb327921e6', 'type': 'tool_call'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k9/fclgtm1j483d4r4tbjfzpz1w0000gn/T/ipykernel_5603/1967508518.py:40: LangGraphDeprecationWarning: ToolInvocation is deprecated as of version 0.2.0 and will be removed in 0.3.0. Use langgraph.prebuilt.ToolNode instead.\n",
      "  content=str(await executor.ainvoke(ToolInvocation(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for TavilyInput\n  Input should be a valid dictionary or instance of TavilyInput [type=model_type, input_value=ToolInvocation(tool='sear...ial election favorite'}), input_type=ToolInvocation]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[348], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m init_msg \u001b[38;5;241m=\u001b[39m [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho is the favoite to win the 2024 US presidential election?\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m chat_graph\u001b[38;5;241m.\u001b[39mastream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: init_msg}):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m event\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(value)\n",
      "File \u001b[0;32m~/miniconda3/envs/fashion_analyzer/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1493\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1488\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   1489\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   1490\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   1491\u001b[0m     manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   1492\u001b[0m ):\n\u001b[0;32m-> 1493\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39matick(\n\u001b[1;32m   1494\u001b[0m         loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   1495\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   1496\u001b[0m         retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   1497\u001b[0m         get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   1498\u001b[0m     ):\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[1;32m   1501\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "File \u001b[0;32m~/miniconda3/envs/fashion_analyzer/lib/python3.12/site-packages/langgraph/pregel/runner.py:130\u001b[0m, in \u001b[0;36mPregelRunner.atick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    128\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(t, retry_policy, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_astream)\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/fashion_analyzer/lib/python3.12/site-packages/langgraph/pregel/retry.py:102\u001b[0m, in \u001b[0;36marun_with_retry\u001b[0;34m(task, retry_policy, stream)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mainvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fashion_analyzer/lib/python3.12/site-packages/langgraph/utils/runnable.py:428\u001b[0m, in \u001b[0;36mRunnableSeq.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     coro \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ASYNCIO_ACCEPTS_CONTEXT:\n\u001b[0;32m--> 428\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro)\n",
      "File \u001b[0;32m~/miniconda3/envs/fashion_analyzer/lib/python3.12/site-packages/langgraph/utils/runnable.py:211\u001b[0m, in \u001b[0;36mRunnableCallable.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ASYNCIO_ACCEPTS_CONTEXT:\n\u001b[1;32m    210\u001b[0m     coro \u001b[38;5;241m=\u001b[39m cast(Coroutine[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, Any], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m--> 211\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[345], line 40\u001b[0m, in \u001b[0;36maction\u001b[0;34m(executor, state)\u001b[0m\n\u001b[1;32m     33\u001b[0m tool_call \u001b[38;5;241m=\u001b[39m last_message\u001b[38;5;241m.\u001b[39mtool_calls[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(tool_call)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     37\u001b[0m         ToolMessage(\n\u001b[1;32m     38\u001b[0m             tool_call_id\u001b[38;5;241m=\u001b[39mtool_call[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     39\u001b[0m             name\u001b[38;5;241m=\u001b[39mtool_call[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m---> 40\u001b[0m             content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;01mawait\u001b[39;00m executor\u001b[38;5;241m.\u001b[39mainvoke(ToolInvocation(\n\u001b[1;32m     41\u001b[0m                 tool\u001b[38;5;241m=\u001b[39mtool_call[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     42\u001b[0m                 tool_input\u001b[38;5;241m=\u001b[39mtool_call[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     43\u001b[0m             ))),\n\u001b[1;32m     44\u001b[0m         )\n\u001b[1;32m     45\u001b[0m     ]\n\u001b[1;32m     46\u001b[0m }\n",
      "File \u001b[0;32m~/miniconda3/envs/fashion_analyzer/lib/python3.12/site-packages/langgraph/utils/runnable.py:215\u001b[0m, in \u001b[0;36mRunnableCallable.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniconda3/envs/fashion_analyzer/lib/python3.12/site-packages/langchain_core/tools/base.py:494\u001b[0m, in \u001b[0;36mBaseTool.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mainvoke\u001b[39m(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m, ToolCall],\n\u001b[1;32m    490\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    492\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    493\u001b[0m     tool_input, kwargs \u001b[38;5;241m=\u001b[39m _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marun(tool_input, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/fashion_analyzer/lib/python3.12/site-packages/langchain_core/tools/base.py:804\u001b[0m, in \u001b[0;36mBaseTool.arun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[0;32m--> 804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[1;32m    806\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/fashion_analyzer/lib/python3.12/site-packages/langchain_core/tools/base.py:757\u001b[0m, in \u001b[0;36mBaseTool.arun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m error_to_raise: Optional[Union[\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 757\u001b[0m     tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    758\u001b[0m     child_config \u001b[38;5;241m=\u001b[39m patch_config(config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child())\n\u001b[1;32m    759\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n",
      "File \u001b[0;32m~/miniconda3/envs/fashion_analyzer/lib/python3.12/site-packages/langchain_core/tools/base.py:574\u001b[0m, in \u001b[0;36mBaseTool._to_args_and_kwargs\u001b[0;34m(self, tool_input)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_args_and_kwargs\u001b[39m(\u001b[38;5;28mself\u001b[39m, tool_input: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[0;32m--> 574\u001b[0m     tool_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/fashion_analyzer/lib/python3.12/site-packages/langchain_core/tools/base.py:516\u001b[0m, in \u001b[0;36mBaseTool._parse_input\u001b[0;34m(self, tool_input)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModel):\n\u001b[0;32m--> 516\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43minput_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m         result_dict \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mmodel_dump()\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModelV1):\n",
      "File \u001b[0;32m~/miniconda3/envs/fashion_analyzer/lib/python3.12/site-packages/pydantic/main.py:568\u001b[0m, in \u001b[0;36mBaseModel.model_validate\u001b[0;34m(cls, obj, strict, from_attributes, context)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    567\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for TavilyInput\n  Input should be a valid dictionary or instance of TavilyInput [type=model_type, input_value=ToolInvocation(tool='sear...ial election favorite'}), input_type=ToolInvocation]\n    For further information visit https://errors.pydantic.dev/2.8/v/model_type"
     ]
    }
   ],
   "source": [
    "init_msg = [HumanMessage(content=\"Who is the favoite to win the 2024 US presidential election?\")]\n",
    "async for event in chat_graph.astream({\"messages\": init_msg}):\n",
    "    for value in event.values():\n",
    "        print(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashion_analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
